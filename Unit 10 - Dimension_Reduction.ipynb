{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dimension Reduction: converting a large set of data with large number of dimensions to fewer dimensions ensuring that it conveys the information concisely"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Four V's of big data: Volume, velocity, variety, veracity. DR focuses on Volume and Velocity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Colinearity: determines whether or not to drop variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Missing Values: Potentially drop a variable altogether if there is too much missing data. Can impute values as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection and Dimension Reduction\n",
    "\n",
    "* Beginners Guide To Dimension Reduction Techniques: https://www.analyticsvidhya.com/blog/2015/07/dimension-reduction-methods/\n",
    "* Feature Selection For Machine Learning in Python: https://machinelearningmastery.com/feature-selection-machine-learning-python/\n",
    "* The Ultimate Guide to 12 Dimensionality Reduction Techniques: https://www.analyticsvidhya.com/blog/2018/08/dimensionality-reduction-techniques-python/\n",
    "* PCA using Python (scikit-learn): https://towardsdatascience.com/pca-using-python-scikit-learn-e653f8989e60\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np              \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x115d432d0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv(\"diabetes.csv\")\n",
    "df.plot.scatter(x='weight', y='waist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.lmplot(x='weight',y='waist',data=df,fit_reg=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                  0\n",
       "chol                1\n",
       "stab.glu            0\n",
       "hdl                 1\n",
       "ratio               1\n",
       "glyhb              13\n",
       "location            0\n",
       "age                 0\n",
       "gender              0\n",
       "height              5\n",
       "weight              1\n",
       "frame              12\n",
       "bp.1s             382\n",
       "bp.1d             382\n",
       "waist               2\n",
       "hip                 2\n",
       "wellness_score      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"diabetes_missing_vals.csv\")\n",
    "\n",
    "# Let's look at how many missing values we have in our dataset\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(403, 17)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looking at the shape of our dataframe will allow us to see a total number of records\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                0.000000\n",
       "chol              0.002481\n",
       "stab.glu          0.000000\n",
       "hdl               0.002481\n",
       "ratio             0.002481\n",
       "glyhb             0.032258\n",
       "location          0.000000\n",
       "age               0.000000\n",
       "gender            0.000000\n",
       "height            0.012407\n",
       "weight            0.002481\n",
       "frame             0.029777\n",
       "bp.1s             0.947891\n",
       "bp.1d             0.947891\n",
       "waist             0.004963\n",
       "hip               0.004963\n",
       "wellness_score    0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the percentage of missing values\n",
    "df.isnull().sum() / df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With such a high amount of missing values in \"bp.1s\" and \"bp.1d\", we can consider dropping these predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Low Variance\n",
    "* A constant variable (all observations have same value)\n",
    "* It cannot improve the power of model it has zero variance. \n",
    "* We should drop variables that have low variance compared to others because these variables will not explain the variation in response variables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                11881.122124\n",
       "chol                 44.445557\n",
       "stab.glu             53.076655\n",
       "hdl                  17.262626\n",
       "ratio                 1.727886\n",
       "glyhb                 2.242595\n",
       "age                  16.312333\n",
       "height                3.918515\n",
       "weight               40.340666\n",
       "bp.1s                30.962189\n",
       "bp.1d                14.672780\n",
       "waist                 5.729313\n",
       "hip                   5.656713\n",
       "wellness_score        0.000050\n",
       "dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df.std()\n",
    "#consider as well\n",
    "\n",
    "df.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                1.411611e+08\n",
       "chol              1.975408e+03\n",
       "stab.glu          2.817131e+03\n",
       "hdl               2.979982e+02\n",
       "ratio             2.985590e+00\n",
       "glyhb             5.029232e+00\n",
       "age               2.660922e+02\n",
       "height            1.535476e+01\n",
       "weight            1.627369e+03\n",
       "bp.1s             9.586571e+02\n",
       "bp.1d             2.152905e+02\n",
       "waist             3.282502e+01\n",
       "hip               3.199840e+01\n",
       "wellness_score    2.483373e-09\n",
       "dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We see that there is barely any variance among wellness_scores across patients\n",
    "df.var()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could consider removing wellness score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "female    401\n",
       "male        2\n",
       "Name: gender, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"gender\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With \"gender\" having only 2 male points, then you can remove the 2 instances (rows) with males and move the \"gender\" variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collinearity\n",
    "* Variables (dimensions) with similar information or variation are called “Multicollinear”. \n",
    "* Dimensions exhibiting higher correlation can lower down the performance of model. \n",
    "* It is not good to have multiple variables of similar information or variation \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>chol</th>\n",
       "      <th>stab.glu</th>\n",
       "      <th>hdl</th>\n",
       "      <th>ratio</th>\n",
       "      <th>glyhb</th>\n",
       "      <th>location</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>frame</th>\n",
       "      <th>bp.1s</th>\n",
       "      <th>bp.1d</th>\n",
       "      <th>waist</th>\n",
       "      <th>hip</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000</td>\n",
       "      <td>203.0</td>\n",
       "      <td>82</td>\n",
       "      <td>56.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>4.31</td>\n",
       "      <td>Buckingham</td>\n",
       "      <td>46</td>\n",
       "      <td>female</td>\n",
       "      <td>62.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>medium</td>\n",
       "      <td>118.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1001</td>\n",
       "      <td>165.0</td>\n",
       "      <td>97</td>\n",
       "      <td>24.0</td>\n",
       "      <td>6.9</td>\n",
       "      <td>4.44</td>\n",
       "      <td>Buckingham</td>\n",
       "      <td>29</td>\n",
       "      <td>female</td>\n",
       "      <td>64.0</td>\n",
       "      <td>218.0</td>\n",
       "      <td>large</td>\n",
       "      <td>112.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>48.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1002</td>\n",
       "      <td>228.0</td>\n",
       "      <td>92</td>\n",
       "      <td>37.0</td>\n",
       "      <td>6.2</td>\n",
       "      <td>4.64</td>\n",
       "      <td>Buckingham</td>\n",
       "      <td>58</td>\n",
       "      <td>female</td>\n",
       "      <td>61.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>large</td>\n",
       "      <td>190.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>57.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1003</td>\n",
       "      <td>78.0</td>\n",
       "      <td>93</td>\n",
       "      <td>12.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>4.63</td>\n",
       "      <td>Buckingham</td>\n",
       "      <td>67</td>\n",
       "      <td>male</td>\n",
       "      <td>67.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>large</td>\n",
       "      <td>110.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1005</td>\n",
       "      <td>249.0</td>\n",
       "      <td>90</td>\n",
       "      <td>28.0</td>\n",
       "      <td>8.9</td>\n",
       "      <td>7.72</td>\n",
       "      <td>Buckingham</td>\n",
       "      <td>64</td>\n",
       "      <td>male</td>\n",
       "      <td>68.0</td>\n",
       "      <td>183.0</td>\n",
       "      <td>medium</td>\n",
       "      <td>138.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>41.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id   chol  stab.glu   hdl  ratio  glyhb    location age  gender  height  \\\n",
       "0  1000  203.0        82  56.0    3.6   4.31  Buckingham  46  female    62.0   \n",
       "1  1001  165.0        97  24.0    6.9   4.44  Buckingham  29  female    64.0   \n",
       "2  1002  228.0        92  37.0    6.2   4.64  Buckingham  58  female    61.0   \n",
       "3  1003   78.0        93  12.0    6.5   4.63  Buckingham  67    male    67.0   \n",
       "4  1005  249.0        90  28.0    8.9   7.72  Buckingham  64    male    68.0   \n",
       "\n",
       "   weight   frame  bp.1s  bp.1d  waist   hip  \n",
       "0   121.0  medium  118.0   59.0   29.0  38.0  \n",
       "1   218.0   large  112.0   68.0   46.0  48.0  \n",
       "2   256.0   large  190.0   92.0   49.0  57.0  \n",
       "3   119.0   large  110.0   50.0   33.0  38.0  \n",
       "4   183.0  medium  138.0   80.0   44.0  41.0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"diabetes.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>chol</th>\n",
       "      <th>stab.glu</th>\n",
       "      <th>hdl</th>\n",
       "      <th>ratio</th>\n",
       "      <th>glyhb</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>bp.1s</th>\n",
       "      <th>bp.1d</th>\n",
       "      <th>waist</th>\n",
       "      <th>hip</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.059243</td>\n",
       "      <td>0.009315</td>\n",
       "      <td>0.059255</td>\n",
       "      <td>-0.034094</td>\n",
       "      <td>0.010378</td>\n",
       "      <td>-0.036948</td>\n",
       "      <td>-0.018658</td>\n",
       "      <td>0.013715</td>\n",
       "      <td>0.084001</td>\n",
       "      <td>-0.008123</td>\n",
       "      <td>0.048658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chol</th>\n",
       "      <td>0.059243</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.150092</td>\n",
       "      <td>0.186581</td>\n",
       "      <td>0.475521</td>\n",
       "      <td>0.247099</td>\n",
       "      <td>-0.058858</td>\n",
       "      <td>0.066889</td>\n",
       "      <td>0.203344</td>\n",
       "      <td>0.171605</td>\n",
       "      <td>0.124489</td>\n",
       "      <td>0.079402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stab.glu</th>\n",
       "      <td>0.009315</td>\n",
       "      <td>0.150092</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.161899</td>\n",
       "      <td>0.280349</td>\n",
       "      <td>0.749236</td>\n",
       "      <td>0.090669</td>\n",
       "      <td>0.185453</td>\n",
       "      <td>0.166467</td>\n",
       "      <td>0.022014</td>\n",
       "      <td>0.218446</td>\n",
       "      <td>0.133502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hdl</th>\n",
       "      <td>0.059255</td>\n",
       "      <td>0.186581</td>\n",
       "      <td>-0.161899</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.686907</td>\n",
       "      <td>-0.149145</td>\n",
       "      <td>-0.101419</td>\n",
       "      <td>-0.290983</td>\n",
       "      <td>0.019804</td>\n",
       "      <td>0.065732</td>\n",
       "      <td>-0.268369</td>\n",
       "      <td>-0.210060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ratio</th>\n",
       "      <td>-0.034094</td>\n",
       "      <td>0.475521</td>\n",
       "      <td>0.280349</td>\n",
       "      <td>-0.686907</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.328665</td>\n",
       "      <td>0.094335</td>\n",
       "      <td>0.281649</td>\n",
       "      <td>0.119386</td>\n",
       "      <td>0.048193</td>\n",
       "      <td>0.304162</td>\n",
       "      <td>0.194622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>glyhb</th>\n",
       "      <td>0.010378</td>\n",
       "      <td>0.247099</td>\n",
       "      <td>0.749236</td>\n",
       "      <td>-0.149145</td>\n",
       "      <td>0.328665</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.063023</td>\n",
       "      <td>0.171882</td>\n",
       "      <td>0.197936</td>\n",
       "      <td>0.032375</td>\n",
       "      <td>0.226184</td>\n",
       "      <td>0.141401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>height</th>\n",
       "      <td>-0.036948</td>\n",
       "      <td>-0.058858</td>\n",
       "      <td>0.090669</td>\n",
       "      <td>-0.101419</td>\n",
       "      <td>0.094335</td>\n",
       "      <td>0.063023</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.251251</td>\n",
       "      <td>-0.047827</td>\n",
       "      <td>0.038598</td>\n",
       "      <td>0.051094</td>\n",
       "      <td>-0.107832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weight</th>\n",
       "      <td>-0.018658</td>\n",
       "      <td>0.066889</td>\n",
       "      <td>0.185453</td>\n",
       "      <td>-0.290983</td>\n",
       "      <td>0.281649</td>\n",
       "      <td>0.171882</td>\n",
       "      <td>0.251251</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.090873</td>\n",
       "      <td>0.175956</td>\n",
       "      <td>0.849855</td>\n",
       "      <td>0.829115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bp.1s</th>\n",
       "      <td>0.013715</td>\n",
       "      <td>0.203344</td>\n",
       "      <td>0.166467</td>\n",
       "      <td>0.019804</td>\n",
       "      <td>0.119386</td>\n",
       "      <td>0.197936</td>\n",
       "      <td>-0.047827</td>\n",
       "      <td>0.090873</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.596557</td>\n",
       "      <td>0.196489</td>\n",
       "      <td>0.136655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bp.1d</th>\n",
       "      <td>0.084001</td>\n",
       "      <td>0.171605</td>\n",
       "      <td>0.022014</td>\n",
       "      <td>0.065732</td>\n",
       "      <td>0.048193</td>\n",
       "      <td>0.032375</td>\n",
       "      <td>0.038598</td>\n",
       "      <td>0.175956</td>\n",
       "      <td>0.596557</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.167110</td>\n",
       "      <td>0.145805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>waist</th>\n",
       "      <td>-0.008123</td>\n",
       "      <td>0.124489</td>\n",
       "      <td>0.218446</td>\n",
       "      <td>-0.268369</td>\n",
       "      <td>0.304162</td>\n",
       "      <td>0.226184</td>\n",
       "      <td>0.051094</td>\n",
       "      <td>0.849855</td>\n",
       "      <td>0.196489</td>\n",
       "      <td>0.167110</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.837080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hip</th>\n",
       "      <td>0.048658</td>\n",
       "      <td>0.079402</td>\n",
       "      <td>0.133502</td>\n",
       "      <td>-0.210060</td>\n",
       "      <td>0.194622</td>\n",
       "      <td>0.141401</td>\n",
       "      <td>-0.107832</td>\n",
       "      <td>0.829115</td>\n",
       "      <td>0.136655</td>\n",
       "      <td>0.145805</td>\n",
       "      <td>0.837080</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                id      chol  stab.glu       hdl     ratio     glyhb  \\\n",
       "id        1.000000  0.059243  0.009315  0.059255 -0.034094  0.010378   \n",
       "chol      0.059243  1.000000  0.150092  0.186581  0.475521  0.247099   \n",
       "stab.glu  0.009315  0.150092  1.000000 -0.161899  0.280349  0.749236   \n",
       "hdl       0.059255  0.186581 -0.161899  1.000000 -0.686907 -0.149145   \n",
       "ratio    -0.034094  0.475521  0.280349 -0.686907  1.000000  0.328665   \n",
       "glyhb     0.010378  0.247099  0.749236 -0.149145  0.328665  1.000000   \n",
       "height   -0.036948 -0.058858  0.090669 -0.101419  0.094335  0.063023   \n",
       "weight   -0.018658  0.066889  0.185453 -0.290983  0.281649  0.171882   \n",
       "bp.1s     0.013715  0.203344  0.166467  0.019804  0.119386  0.197936   \n",
       "bp.1d     0.084001  0.171605  0.022014  0.065732  0.048193  0.032375   \n",
       "waist    -0.008123  0.124489  0.218446 -0.268369  0.304162  0.226184   \n",
       "hip       0.048658  0.079402  0.133502 -0.210060  0.194622  0.141401   \n",
       "\n",
       "            height    weight     bp.1s     bp.1d     waist       hip  \n",
       "id       -0.036948 -0.018658  0.013715  0.084001 -0.008123  0.048658  \n",
       "chol     -0.058858  0.066889  0.203344  0.171605  0.124489  0.079402  \n",
       "stab.glu  0.090669  0.185453  0.166467  0.022014  0.218446  0.133502  \n",
       "hdl      -0.101419 -0.290983  0.019804  0.065732 -0.268369 -0.210060  \n",
       "ratio     0.094335  0.281649  0.119386  0.048193  0.304162  0.194622  \n",
       "glyhb     0.063023  0.171882  0.197936  0.032375  0.226184  0.141401  \n",
       "height    1.000000  0.251251 -0.047827  0.038598  0.051094 -0.107832  \n",
       "weight    0.251251  1.000000  0.090873  0.175956  0.849855  0.829115  \n",
       "bp.1s    -0.047827  0.090873  1.000000  0.596557  0.196489  0.136655  \n",
       "bp.1d     0.038598  0.175956  0.596557  1.000000  0.167110  0.145805  \n",
       "waist     0.051094  0.849855  0.196489  0.167110  1.000000  0.837080  \n",
       "hip      -0.107832  0.829115  0.136655  0.145805  0.837080  1.000000  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>chol</th>\n",
       "      <th>stab.glu</th>\n",
       "      <th>hdl</th>\n",
       "      <th>ratio</th>\n",
       "      <th>glyhb</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>bp.1s</th>\n",
       "      <th>bp.1d</th>\n",
       "      <th>waist</th>\n",
       "      <th>hip</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.059243</td>\n",
       "      <td>0.009315</td>\n",
       "      <td>0.059255</td>\n",
       "      <td>0.034094</td>\n",
       "      <td>0.010378</td>\n",
       "      <td>0.036948</td>\n",
       "      <td>0.018658</td>\n",
       "      <td>0.013715</td>\n",
       "      <td>0.084001</td>\n",
       "      <td>0.008123</td>\n",
       "      <td>0.048658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chol</th>\n",
       "      <td>0.059243</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.150092</td>\n",
       "      <td>0.186581</td>\n",
       "      <td>0.475521</td>\n",
       "      <td>0.247099</td>\n",
       "      <td>0.058858</td>\n",
       "      <td>0.066889</td>\n",
       "      <td>0.203344</td>\n",
       "      <td>0.171605</td>\n",
       "      <td>0.124489</td>\n",
       "      <td>0.079402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stab.glu</th>\n",
       "      <td>0.009315</td>\n",
       "      <td>0.150092</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.161899</td>\n",
       "      <td>0.280349</td>\n",
       "      <td>0.749236</td>\n",
       "      <td>0.090669</td>\n",
       "      <td>0.185453</td>\n",
       "      <td>0.166467</td>\n",
       "      <td>0.022014</td>\n",
       "      <td>0.218446</td>\n",
       "      <td>0.133502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hdl</th>\n",
       "      <td>0.059255</td>\n",
       "      <td>0.186581</td>\n",
       "      <td>0.161899</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.686907</td>\n",
       "      <td>0.149145</td>\n",
       "      <td>0.101419</td>\n",
       "      <td>0.290983</td>\n",
       "      <td>0.019804</td>\n",
       "      <td>0.065732</td>\n",
       "      <td>0.268369</td>\n",
       "      <td>0.210060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ratio</th>\n",
       "      <td>0.034094</td>\n",
       "      <td>0.475521</td>\n",
       "      <td>0.280349</td>\n",
       "      <td>0.686907</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.328665</td>\n",
       "      <td>0.094335</td>\n",
       "      <td>0.281649</td>\n",
       "      <td>0.119386</td>\n",
       "      <td>0.048193</td>\n",
       "      <td>0.304162</td>\n",
       "      <td>0.194622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>glyhb</th>\n",
       "      <td>0.010378</td>\n",
       "      <td>0.247099</td>\n",
       "      <td>0.749236</td>\n",
       "      <td>0.149145</td>\n",
       "      <td>0.328665</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.063023</td>\n",
       "      <td>0.171882</td>\n",
       "      <td>0.197936</td>\n",
       "      <td>0.032375</td>\n",
       "      <td>0.226184</td>\n",
       "      <td>0.141401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>height</th>\n",
       "      <td>0.036948</td>\n",
       "      <td>0.058858</td>\n",
       "      <td>0.090669</td>\n",
       "      <td>0.101419</td>\n",
       "      <td>0.094335</td>\n",
       "      <td>0.063023</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.251251</td>\n",
       "      <td>0.047827</td>\n",
       "      <td>0.038598</td>\n",
       "      <td>0.051094</td>\n",
       "      <td>0.107832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weight</th>\n",
       "      <td>0.018658</td>\n",
       "      <td>0.066889</td>\n",
       "      <td>0.185453</td>\n",
       "      <td>0.290983</td>\n",
       "      <td>0.281649</td>\n",
       "      <td>0.171882</td>\n",
       "      <td>0.251251</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.090873</td>\n",
       "      <td>0.175956</td>\n",
       "      <td>0.849855</td>\n",
       "      <td>0.829115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bp.1s</th>\n",
       "      <td>0.013715</td>\n",
       "      <td>0.203344</td>\n",
       "      <td>0.166467</td>\n",
       "      <td>0.019804</td>\n",
       "      <td>0.119386</td>\n",
       "      <td>0.197936</td>\n",
       "      <td>0.047827</td>\n",
       "      <td>0.090873</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.596557</td>\n",
       "      <td>0.196489</td>\n",
       "      <td>0.136655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bp.1d</th>\n",
       "      <td>0.084001</td>\n",
       "      <td>0.171605</td>\n",
       "      <td>0.022014</td>\n",
       "      <td>0.065732</td>\n",
       "      <td>0.048193</td>\n",
       "      <td>0.032375</td>\n",
       "      <td>0.038598</td>\n",
       "      <td>0.175956</td>\n",
       "      <td>0.596557</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.167110</td>\n",
       "      <td>0.145805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>waist</th>\n",
       "      <td>0.008123</td>\n",
       "      <td>0.124489</td>\n",
       "      <td>0.218446</td>\n",
       "      <td>0.268369</td>\n",
       "      <td>0.304162</td>\n",
       "      <td>0.226184</td>\n",
       "      <td>0.051094</td>\n",
       "      <td>0.849855</td>\n",
       "      <td>0.196489</td>\n",
       "      <td>0.167110</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.837080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hip</th>\n",
       "      <td>0.048658</td>\n",
       "      <td>0.079402</td>\n",
       "      <td>0.133502</td>\n",
       "      <td>0.210060</td>\n",
       "      <td>0.194622</td>\n",
       "      <td>0.141401</td>\n",
       "      <td>0.107832</td>\n",
       "      <td>0.829115</td>\n",
       "      <td>0.136655</td>\n",
       "      <td>0.145805</td>\n",
       "      <td>0.837080</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                id      chol  stab.glu       hdl     ratio     glyhb  \\\n",
       "id        1.000000  0.059243  0.009315  0.059255  0.034094  0.010378   \n",
       "chol      0.059243  1.000000  0.150092  0.186581  0.475521  0.247099   \n",
       "stab.glu  0.009315  0.150092  1.000000  0.161899  0.280349  0.749236   \n",
       "hdl       0.059255  0.186581  0.161899  1.000000  0.686907  0.149145   \n",
       "ratio     0.034094  0.475521  0.280349  0.686907  1.000000  0.328665   \n",
       "glyhb     0.010378  0.247099  0.749236  0.149145  0.328665  1.000000   \n",
       "height    0.036948  0.058858  0.090669  0.101419  0.094335  0.063023   \n",
       "weight    0.018658  0.066889  0.185453  0.290983  0.281649  0.171882   \n",
       "bp.1s     0.013715  0.203344  0.166467  0.019804  0.119386  0.197936   \n",
       "bp.1d     0.084001  0.171605  0.022014  0.065732  0.048193  0.032375   \n",
       "waist     0.008123  0.124489  0.218446  0.268369  0.304162  0.226184   \n",
       "hip       0.048658  0.079402  0.133502  0.210060  0.194622  0.141401   \n",
       "\n",
       "            height    weight     bp.1s     bp.1d     waist       hip  \n",
       "id        0.036948  0.018658  0.013715  0.084001  0.008123  0.048658  \n",
       "chol      0.058858  0.066889  0.203344  0.171605  0.124489  0.079402  \n",
       "stab.glu  0.090669  0.185453  0.166467  0.022014  0.218446  0.133502  \n",
       "hdl       0.101419  0.290983  0.019804  0.065732  0.268369  0.210060  \n",
       "ratio     0.094335  0.281649  0.119386  0.048193  0.304162  0.194622  \n",
       "glyhb     0.063023  0.171882  0.197936  0.032375  0.226184  0.141401  \n",
       "height    1.000000  0.251251  0.047827  0.038598  0.051094  0.107832  \n",
       "weight    0.251251  1.000000  0.090873  0.175956  0.849855  0.829115  \n",
       "bp.1s     0.047827  0.090873  1.000000  0.596557  0.196489  0.136655  \n",
       "bp.1d     0.038598  0.175956  0.596557  1.000000  0.167110  0.145805  \n",
       "waist     0.051094  0.849855  0.196489  0.167110  1.000000  0.837080  \n",
       "hip       0.107832  0.829115  0.136655  0.145805  0.837080  1.000000  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.corr().abs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hip       hip         1.000000\n",
       "waist     waist       1.000000\n",
       "chol      chol        1.000000\n",
       "stab.glu  stab.glu    1.000000\n",
       "hdl       hdl         1.000000\n",
       "                        ...   \n",
       "id        glyhb       0.010378\n",
       "stab.glu  id          0.009315\n",
       "id        stab.glu    0.009315\n",
       "waist     id          0.008123\n",
       "id        waist       0.008123\n",
       "Length: 144, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#absolute value first, we don't care if positive or negative\n",
    "#sort means the first few are all 1, self-correlantion\n",
    "#very useful tool \n",
    "c = df.corr().abs()\n",
    "\n",
    "#unstack makes it into a list and makes information easier to digest\n",
    "s = c.unstack()\n",
    "so = s.sort_values(kind=\"quicksort\", ascending=False)\n",
    "so"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Univariate Feature Selection\n",
    "* Statistical tests can be used to select those features that have the strongest relationship with the output variable.\n",
    "* The scikit-learn library provides the SelectKBest class that can be used with a suite of different statistical tests to select a specific number of features.\n",
    "* The example below uses the chi squared (chi^2) statistical test for non-negative features to select k of the best features from the Pima Indians onset of diabetes dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chi^2 how often categorical variables occurs. Use modules to determine which variables to use.\n",
    "\n",
    "- Uses a variables' frequencies to determine relationship between variables.\n",
    "- Determines whether the distribution in one variable depends on the distribution of another variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 111.52  1411.887   17.605   53.108 2175.565  127.669  181.304]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "df = pd.read_csv(\"pima_indians_diabetes.csv\")\n",
    "#Note this is not to be done in practice, dropna()\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "X = df[[\"Pregnancies\", \"Glucose\", \"BloodPressure\", \"SkinThickness\", \"Insulin\", \"BMI\", \"Age\"]]\n",
    "Y = df['Outcome']\n",
    "# feature extraction, select \"4\" which are most meaninful\n",
    "test = SelectKBest(score_func=chi2, k=4)\n",
    "fit = test.fit(X, Y)\n",
    "# summarize scores, (pairwise)\n",
    "np.set_printoptions(precision=3)\n",
    "print(fit.scores_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Insulin, 5th, would be best predictor, can consider eliminating others \n",
    "#(lower score = cannot reject null hypothesis)\n",
    "#view the results in a dataframe\n",
    "scored_predictors = pd.concat([pd.Series(X.columns),pd.Series(fit.scores_)], axis =1)\n",
    "scored_predictors.columns = [\"Features\",\"Scores\"]\n",
    "scored_predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recursive Feature Selection / Elimination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Recursive Feature Selection: Linear Regression Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "#Load data\n",
    "df = pd.read_csv(\"diabetes_missing_vals.csv\")\n",
    "df = df[[\"stab.glu\", \"hdl\", \"ratio\", \"glyhb\", \"age\", \"height\", \"weight\", \"hip\", \"chol\"]]\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "#Select Features/Response\n",
    "X = df[[\"stab.glu\", \"hdl\", \"ratio\", \"glyhb\", \"age\", \"height\", \"weight\", \"hip\"]]\n",
    "Y = df[\"chol\"]\n",
    "\n",
    "#Instantiate the model\n",
    "#Note the lack of Test/Train/Split\n",
    "#Our goal is Feature Selection, not training a model \n",
    "model = LinearRegression()\n",
    "\n",
    "rfe = RFE(model, 3)\n",
    "fit = rfe.fit(X, Y)\n",
    "#Number of feature to select = 3\n",
    "#Finding the smallest sum-squared-error (SSE)\n",
    "print(\"Num Features:\",  fit.n_features_)\n",
    "print(\"Selected Features: \", fit.support_)\n",
    "print(\"Feature Ranking: \",  fit.ranking_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Recursive Feature Elimination: Logistic Regression Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Very similar process\n",
    "#Learn more about Linear vs. Logistic Regression in the references \n",
    "\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "df = pd.read_csv(\"diabetes_missing_vals.csv\")\n",
    "\n",
    "\n",
    "df = df[[\"stab.glu\", \"hdl\", \"ratio\", \"glyhb\", \"age\", \"height\", \"weight\", \"hip\", \"chol\"]]\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "X = df[[\"stab.glu\", \"hdl\", \"ratio\", \"glyhb\", \"age\", \"height\", \"weight\"]]\n",
    "Y = df[\"chol\"]\n",
    "\n",
    "\n",
    "model = LogisticRegression()\n",
    "\n",
    "\n",
    "rfe = RFE(model, 3)\n",
    "fit = rfe.fit(X, Y)\n",
    "print(\"Num Features:\",  fit.n_features_)\n",
    "print(\"Selected Features: \", fit.support_)\n",
    "print(\"Feature Ranking: \",  fit.ranking_)\n",
    "\n",
    "#Note the differences between suggested feature in Linear vs. Logistic Regression "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Outcome of feature elimination\n",
    "\n",
    "We can see the outcome from our feature selection if we use the suggested features. Note that this would probably not be done in practice in this exact same way (more clearning, validation would follow) but you can see the (incremental) benefit of our feature selection from our Linear Regression above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv(\"diabetes_missing_vals.csv\")\n",
    "df = df[[\"stab.glu\", \"hdl\", \"ratio\", \"glyhb\", \"age\", \"height\", \"weight\", \"hip\", \"chol\"]]\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "#Calculate Score with all Variables\n",
    "X_all = df[[\"stab.glu\", \"hdl\", \"ratio\", \"glyhb\", \"age\", \"height\", \"weight\", \"hip\"]]\n",
    "y_all = df[\"chol\"]\n",
    "\n",
    "\n",
    "X_all_train, X_all_test, y_all_train, y_all_test = train_test_split(X_all, y_all, test_size=0.20, random_state = 1)\n",
    "model = LinearRegression()\n",
    "model.fit(X_all_train, y_all_train)\n",
    "\n",
    "y_pred = model.predict(X_all_test)\n",
    "print(\"The score for all variables is:\",model.score(X_all_test, y_all_test))\n",
    "\n",
    "#Caluculate SCore with selected/reduced variables based on info from RFE\n",
    "X_reduc = df[[ \"hdl\", \"ratio\", \"height\"]]\n",
    "y_reduc = df[\"chol\"]\n",
    "\n",
    "\n",
    "X_reduc_train, X_reduc_test, y_reduc_train, y_reduc_test = train_test_split(X_reduc, y_reduc, test_size=0.20, random_state = 1)\n",
    "model = LinearRegression()\n",
    "model.fit(X_reduc_train, y_reduc_train)\n",
    "\n",
    "y_pred = model.predict(X_reduc_test)\n",
    "print(\"The score for all variables is:\",model.score(X_reduc_test, y_reduc_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Data\n",
    "\n",
    "This dataset is originally from the National Institute of Diabetes and Digestive and Kidney Diseases. The objective of the dataset is to diagnostically predict whether or not a patient has diabetes, based on certain diagnostic measurements included in the dataset. Several constraints were placed on the selection of these instances from a larger database. In particular, all patients here are females at least 21 years old of Pima Indian heritage.\n",
    "\n",
    "https://www.kaggle.com/uciml/pima-indians-diabetes-database/version/1#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the data into a Pandas DataFrame\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv('pima_indians_diabetes.csv')\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define X and y\n",
    "X = df[['Pregnancies', 'BloodPressure', 'SkinThickness', 'Insulin',\n",
    "       'BMI', 'DiabetesPedigreeFunction', 'Age']]\n",
    "\n",
    "#looking to predict a glucose value\n",
    "y = df['Glucose']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split X and y into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# instantiate model\n",
    "# max 10 decision points, any further = pruning \n",
    "model = RandomForestRegressor(random_state=1, max_depth=10)\n",
    "\n",
    "# fit model\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make estimations for the testing set\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding the ranking of features/variables\n",
    "features = X.columns\n",
    "print(features)\n",
    "importances = model.feature_importances_\n",
    "print(importances)\n",
    "#higher the value, higher the importance\n",
    "#consider dimensions with more importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some additional validation for review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#note that low correlation can still be a good predictor \n",
    "df[['Insulin','Glucose']].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.argsort(importances)[-9:]  # top 10 features\n",
    "plt.title('Feature Importances')\n",
    "plt.barh(range(len(indices)), importances[indices], color='b', align='center')\n",
    "plt.yticks(range(len(indices)), [features[i] for i in indices])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest Classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define X and y\n",
    "X = df[['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin',\n",
    "       'BMI', 'DiabetesPedigreeFunction', 'Age']]\n",
    "\n",
    "#looking to predict a binary outcome of having diabetes\n",
    "y = df['Outcome']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split X and y into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note the difference for what we import\n",
    "#Change from \"RF Regressor\" to \"RF Classifer\"\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# instantiate model\n",
    "model = RandomForestClassifier(random_state=1, max_depth=10)\n",
    "\n",
    "# fit model\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make estimations for the testing set\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding the ranking of features/variables\n",
    "features = X.columns\n",
    "print(features)\n",
    "importances = model.feature_importances_\n",
    "print(importances)\n",
    "#higher the value, higher the importance, consider for more importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note the difference in Classification variables/features compared to our Regression ranking\n",
    "indices = np.argsort(importances)[-9:]  # top 10 features\n",
    "plt.title('Feature Importances')\n",
    "plt.barh(range(len(indices)), importances[indices], color='b', align='center')\n",
    "plt.yticks(range(len(indices)), [features[i] for i in indices])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Factor Analysis\n",
    "* Highly correlated features can be grouped by their correlations\n",
    "* All variables in a particular group can be highly correlated among themselves but have low correlation with variables of other group(s). \n",
    "* Each group represents a single underlying construct or factor. \n",
    "* These factors are smaller in number as compared to large number of dimensions. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import FactorAnalysis\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv(\"diabetes_missing_vals.csv\")\n",
    "\n",
    "X = df[[\"stab.glu\", \"hdl\", \"ratio\", \"glyhb\", \"age\", \"height\", \"weight\", \"hip\"]]\n",
    "X.dropna(inplace=True)\n",
    "\n",
    "FA = FactorAnalysis(n_components = 3).fit_transform(X.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert factor components into a dataframe\n",
    "fa_df = pd.DataFrame(data=FA, columns=['component1','component2','component3'])\n",
    "fa_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fa_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concat = pd.concat([X, fa_df], axis=1)\n",
    "df_concat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "plt.title('Factor Analysis Components')\n",
    "plt.scatter(FA[:,0], FA[:,1])\n",
    "plt.scatter(FA[:,1], FA[:,2])\n",
    "plt.scatter(FA[:,2],FA[:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Principal Component Analysis\n",
    "* Features are transformed into a new set of features\n",
    "* These new features are linear combination of original features. \n",
    "* These new sets of features are known as principal components. \n",
    "* They are obtained in such a way that first principle component accounts for most of the possible variation of original data\n",
    "* Each succeeding component has the highest possible variance\n",
    "* The second principal component must be orthogonal to the first principal component. In other words, it does its best to capture the variance in the data that is not captured by the first principal component. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "df = pd.read_csv(\"pima_indians_diabetes.csv\")\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "X = df[[\"Pregnancies\", \"Glucose\", \"BloodPressure\", \"SkinThickness\", \"Insulin\", \"BMI\", \"Age\"]]\n",
    "Y = df['Outcome']\n",
    "\n",
    "# feature extraction\n",
    "pca = PCA(n_components=2)\n",
    "fit = pca.fit(X)\n",
    "# summarize components\n",
    "print(\"Explained Variance:\", fit.explained_variance_ratio_)\n",
    "print(\"Components: \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert principal components into a dataframe\n",
    "principalComponents = pca.fit_transform(X)\n",
    "pca_df = pd.DataFrame(data=principalComponents, columns=['component1','component2'])\n",
    "pca_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Original dataframe shape: \")\n",
    "print(df.shape)\n",
    "print(\"PCA dataframe shape: \")\n",
    "print(pca_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot PCA results\n",
    "# colors = ['r', 'g']\n",
    "rng = np.random.RandomState(0)\n",
    "colors = rng.rand(100)\n",
    "pca_df.plot.scatter(x='component1', y='component2', c=colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
